====================================================================================================
input_1 (InputLayer)             (None, 42, 42, 3)     0                                            
____________________________________________________________________________________________________
conv2d_1 (Conv2D)                (None, 42, 42, 64)    15616       input_1[0][0]                    
____________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)        (None, 42, 42, 64)    0           conv2d_1[0][0]                   
____________________________________________________________________________________________________
conv2d_2 (Conv2D)                (None, 42, 42, 64)    36928       leaky_re_lu_1[0][0]              
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 42, 42, 64)    256         conv2d_2[0][0]                   
____________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)        (None, 42, 42, 64)    0           batch_normalization_1[0][0]      
____________________________________________________________________________________________________
conv2d_3 (Conv2D)                (None, 42, 42, 64)    36928       leaky_re_lu_2[0][0]              
____________________________________________________________________________________________________
batch_normalization_2 (BatchNorm (None, 42, 42, 64)    256         conv2d_3[0][0]                   
____________________________________________________________________________________________________
add_1 (Add)                      (None, 42, 42, 64)    0           leaky_re_lu_1[0][0]              
                                                                   batch_normalization_2[0][0]      
____________________________________________________________________________________________________
conv2d_4 (Conv2D)                (None, 42, 42, 64)    36928       add_1[0][0]                      
____________________________________________________________________________________________________
batch_normalization_3 (BatchNorm (None, 42, 42, 64)    256         conv2d_4[0][0]                   
____________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)        (None, 42, 42, 64)    0           batch_normalization_3[0][0]      
____________________________________________________________________________________________________
conv2d_5 (Conv2D)                (None, 42, 42, 64)    36928       leaky_re_lu_3[0][0]              
____________________________________________________________________________________________________
batch_normalization_4 (BatchNorm (None, 42, 42, 64)    256         conv2d_5[0][0]                   
____________________________________________________________________________________________________
add_2 (Add)                      (None, 42, 42, 64)    0           add_1[0][0]                      
                                                                   batch_normalization_4[0][0]      
____________________________________________________________________________________________________
conv2d_6 (Conv2D)                (None, 42, 42, 64)    36928       add_2[0][0]                      
____________________________________________________________________________________________________
batch_normalization_5 (BatchNorm (None, 42, 42, 64)    256         conv2d_6[0][0]                   
____________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)        (None, 42, 42, 64)    0           batch_normalization_5[0][0]      
____________________________________________________________________________________________________
conv2d_7 (Conv2D)                (None, 42, 42, 64)    36928       leaky_re_lu_4[0][0]              
____________________________________________________________________________________________________
batch_normalization_6 (BatchNorm (None, 42, 42, 64)    256         conv2d_7[0][0]                   
____________________________________________________________________________________________________
add_3 (Add)                      (None, 42, 42, 64)    0           add_2[0][0]                      
                                                                   batch_normalization_6[0][0]      
____________________________________________________________________________________________________
conv2d_8 (Conv2D)                (None, 42, 42, 64)    36928       add_3[0][0]                      
____________________________________________________________________________________________________
batch_normalization_7 (BatchNorm (None, 42, 42, 64)    256         conv2d_8[0][0]                   
____________________________________________________________________________________________________
add_4 (Add)                      (None, 42, 42, 64)    0           leaky_re_lu_1[0][0]              
                                                                   batch_normalization_7[0][0]      
____________________________________________________________________________________________________
conv2d_9 (Conv2D)                (None, 42, 42, 128)   8320        add_4[0][0]                      
____________________________________________________________________________________________________
conv2d_10 (Conv2D)               (None, 42, 42, 3)     31107       conv2d_9[0][0]                   
====================================================================================================
Total params: 315,331
Trainable params: 314,435
Non-trainable params: 896
